//include "cpu_gpu_shared.inl"
//include "uniforms.inl"
//include "defines.inl"
//include "globals.inl"
//include "prng.inl"
//include "atom_decls.inl"
//include "bit_packing.inl"
//include "sites.inl"
//include "atoms.inl"
//include "splitmix32.inl"
//include "xoroshiro128starstar.inl"


bool isActiveMem(ivec2 vote_idx) {
	uint center_v = imageLoad(img_vote, vote_idx).x;
	const int R = EVENT_WINDOW_RADIUS*2;
    for (int y = -R; y <= R; ++y) {
        for (int x = -R; x <= R; ++x) {
            int m = abs(x) + abs(y);
            if (m <= R && !(x == 0 && y == 0)) {
				uint v = imageLoad(img_vote, vote_idx + ivec2(x,y)).x;
                if (v >= center_v) {
                    return false;
                }
            }
        }
    }
	return true;
}

void main() {
	if (stage == STAGE_RESET) {
		ivec2 prng_idx = ivec2(gl_GlobalInvocationID.xy);
		ivec2 world_size = imageSize(img_site_bits);
		ivec2 prng_size = imageSize(img_prng_state);
		if (prng_idx.x < prng_size.x && prng_idx.y < prng_size.y) {
			// seed the prng state
			uint state = prng_idx.x + prng_idx.y * prng_size.x;
			uint smix = SplitMix32(state);
			_XORO[0] = SplitMix32(state);
			_XORO[1] = SplitMix32(state);
			_XORO[2] = SplitMix32(state);
			_XORO[3] = SplitMix32(state);
			// crank it a bit just in case to decorrelate
			for (int i = 0; i < 128; ++i)
				XoroshiroNext32();
		

			if (prng_idx.x >= EVENT_WINDOW_RADIUS && prng_idx.y >= EVENT_WINDOW_RADIUS &&
				prng_idx.x < (prng_size.x - EVENT_WINDOW_RADIUS) && prng_idx.y < (prng_size.y - EVENT_WINDOW_RADIUS)) {
			
				ivec2 site_idx = prng_idx - ivec2(EVENT_WINDOW_RADIUS);
				_SITE_IDX = site_idx;
				_SYMMETRY = cSYMMETRY_000L;
				uint tick_counter = dispatch_counter;

				ew(0, new(Empty));
				Init(site_idx, world_size);

				imageStore(img_event_count, site_idx, uvec4(0));
				imageStore(img_dev, site_idx, uvec4(uint(smix&0xffffffff), uint((smix>>32)&0xffffffff), 0, 0));
			}

			imageStore(img_prng_state, prng_idx, xoroshiro128_pack(_XORO));
		}
	} else if (stage == STAGE_CLEAR_STATS) {
		if (gl_GlobalInvocationID.xy == uvec2(0)) {
			for (int i = 0; i < TYPE_COUNT; ++i)
				stats.counts[i] = 0;
			stats.event_count_this_batch = 0;
			stats.event_count_min = 0xffffffff;
			stats.event_count_max = 0;

			site_info.event_layer = uvec4(0);
			site_info.base_layer = uvec4(0);
			site_info.dev = uvec4(0);
		}
	} else if (stage == STAGE_VOTE) {
		uvec2 size = imageSize(img_vote);
		ivec2 vote_idx = ivec2(gl_GlobalInvocationID.xy);

		if (vote_idx.x < size.x && vote_idx.y < size.y) { 
			_XORO = xoroshiro128_unpack(imageLoad(img_prng_state, vote_idx));
			uint center_v = XoroshiroNext32();
			imageStore(img_vote, vote_idx, uvec4(center_v));
			imageStore(img_prng_state, vote_idx, xoroshiro128_pack(_XORO));
		}
	} else if (stage == STAGE_EVENT) {
		uvec2 size = imageSize(img_site_bits);
		ivec2 center_idx = ivec2(gl_GlobalInvocationID.xy);

		// threads may be scheduled "off the image" because they come in blocks, so make sure our thread is actually on top of a valid site
		if (center_idx.x < size.x && center_idx.y < size.y) {
			_SITE_IDX = center_idx;
			ivec2 vote_idx = _SITE_IDX +  ivec2(EVENT_WINDOW_RADIUS*2);				
			if  (isActiveMem(vote_idx)) {

				_XORO = xoroshiro128_unpack(imageLoad(img_prng_state, vote_idx));
				//uvec4 D = uvec4(0);

				Atom S = _SITE_LOAD(ivec2(0,0));
				
				_BEHAVE_DISPATCH(_UNPACK_TYPE(S));

				//D.z = 1; // #HACK site updated signal
				
				atomicAdd(stats.event_count_this_batch, 1);
				
				uint event_count = imageLoad(img_event_count, center_idx).x;
				event_count += 1;
				imageStore(img_event_count, center_idx, uvec4(event_count));
				imageStore(img_prng_state, vote_idx, xoroshiro128_pack(_XORO));
			}
			
			//imageStore(img_dev, center_idx, D);
			
		}
	} else if (stage == STAGE_COMPUTE_STATS) {
		uvec2 size = imageSize(img_site_bits);
		ivec2 center_idx = ivec2(gl_GlobalInvocationID.xy);
		uint type = 0;
		uint count = 0;
		if (center_idx.x < size.x && center_idx.y < size.y) { 
			_SITE_IDX = center_idx;
			_SYMMETRY = cSYMMETRY_000L;
			Atom A = _SITE_LOAD(ivec2(0));
			type = min(_UNPACK_TYPE(A), TYPE_COUNTS-1);
			count = 1;

			//uint event_count = imageLoad(img_event_count, center_idx).x;
			//atomicMin(stats.event_count_min, event_count);
			//atomicMax(stats.event_count_max, event_count);

			if (center_idx == site_info_idx) {
				//site_info.dev = D;
				site_info.event_layer = A;
			}
		}
		atomicAdd(stats.counts[type], count);
	} else if (stage == STAGE_SITE_INFO) {
		if (gl_GlobalInvocationID.xy == uvec2(0)) {
			_SITE_IDX = site_info_idx;
			_SYMMETRY = cSYMMETRY_000L;
			Atom A = _SITE_LOAD(ivec2(0));
			site_info.event_layer = A;

			//uvec4 D = imageLoad(img_dev, center_idx);
			//site_info.dev = D;
		}
	} else if (stage == STAGE_RENDER) {
		uvec2 size = imageSize(img_site_bits);
		ivec2 center_idx = ivec2(gl_GlobalInvocationID.xy);

		// threads may be scheduled "off the image" because they come in blocks, so make sure our thread is actually on top of a valid site
		if (center_idx.x < size.x && center_idx.y < size.y) { 

			// rendering does not support rng, reading from any site other than 0, and hence doesn't require symmetry randomization
			_SITE_IDX = center_idx;
			_SYMMETRY = cSYMMETRY_000L;
		
			ARGB argb = _COLOR_DISPATCH(_UNPACK_TYPE(imageLoad(img_site_bits, center_idx)));

			vec4 col = vec4(argb.yzwx) / 255.0;
	#if 0
			uvec4 R = imageLoad(img_prng_state, center_idx);
			col = mix(col, vec4(vec3(float((R.w>>0)&0xff)/255.0), 1.0), 0.5);
	#endif
	#if 0
			uint event_count = imageLoad(img_event_count, center_idx).x;
			col = mix(col, vec4(vec3(float(event_count) / 40.0), 1.0), 0.5);;
	#endif

	#if 0
			uint event_count = imageLoad(img_event_count, center_idx).x;
			col = vec4(vec3(float(event_count) / 100.0), 1.0);
	#endif
	#if 0
			uvec4 R = imageLoad(img_prng_state, center_idx);
			col = vec4(vec3(float((R.w>>0)&0xff)/255.0), 1.0);
	#endif
	#if 0
			uvec4 R = imageLoad(img_vote, center_idx);
			col = vec4(vec3(float((R.x>>0)&0xff)/255.0), 1.0);
	#endif
			if (center_idx.x == site_info_idx.x && center_idx.y == site_info_idx.y)
				col = vec4(1.0);
			imageStore(img_color, ivec2(center_idx.x, size.y - 1 - center_idx.y), col); //#Y-DOWN
		}
	}
	/*
	if (stage == 0) {
		uvec2 size = imageSize(img_vote);
		ivec2 vote_idx = ivec2(gl_GlobalInvocationID.xy);

		if (vote_idx.x < size.x && vote_idx.y < size.y) { 
			_XORO = xoroshiro128_unpack(imageLoad(img_prng_state, vote_idx));
			uint center_v = XoroshiroNext32();
			imageStore(img_vote, vote_idx, uvec4(center_v));
			imageStore(img_prng_state, vote_idx, xoroshiro128_pack(_XORO));
		}
	} else if (stage == 1) {
		uvec2 size = imageSize(img_site_bits);
		ivec2 center_idx = ivec2(gl_GlobalInvocationID.xy);

		// threads may be scheduled "off the image" because they come in blocks, so make sure our thread is actually on top of a valid site
		if (center_idx.x < size.x && center_idx.y < size.y) {
			_SITE_IDX = center_idx;
			ivec2 vote_idx = _SITE_IDX +  ivec2(EVENT_WINDOW_RADIUS*2);				
			if  (isActiveMem(vote_idx)) {

				_XORO = xoroshiro128_unpack(imageLoad(img_prng_state, vote_idx));
				//uvec4 D = uvec4(0);

				Atom S = _SITE_LOAD(ivec2(0,0));
				
				_BEHAVE_DISPATCH(_UNPACK_TYPE(S));

				//D.z = 1; // #HACK site updated signal
				
				atomicAdd(stats.event_count_this_batch, 1);
				
				uint event_count = imageLoad(img_event_count, center_idx).x;
				event_count += 1;
				imageStore(img_event_count, center_idx, uvec4(event_count));
				imageStore(img_prng_state, vote_idx, xoroshiro128_pack(_XORO));
			}
			
			//imageStore(img_dev, center_idx, D);
			
		}
	}
	*/
}